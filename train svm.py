# -*- coding: utf-8 -*-
import os
import pandas as pd
import numpy as np
from PIL import Image, UnidentifiedImageError
from tqdm import tqdm
import torch
import torch.nn as nn
import torchvision.models as models
import torchvision.transforms as transforms
from sklearn.preprocessing import LabelEncoder, StandardScaler, label_binarize
from sklearn.model_selection import train_test_split
from sklearn.metrics import (classification_report, confusion_matrix, accuracy_score,
                             roc_curve, auc, precision_recall_curve, average_precision_score)
# S·ª≠ d·ª•ng API c·ªët l√µi c·ªßa XGBoost
import xgboost as xgb
import time
import warnings
import gc
import json
import matplotlib.pyplot as plt
import seaborn as sns


# Ghi l·∫°i th·ªùi gian b·∫Øt ƒë·∫ßu t·ªïng th·ªÉ c·ªßa script
script_start_time_main = time.time()


warnings.filterwarnings("ignore", category=UserWarning)
warnings.filterwarnings("ignore", category=FutureWarning)


print("-------------------------------------------------------------")
print("--- Script K·∫øt h·ª£p Annotations v√† Ph√¢n lo·∫°i BI-RADS v5 (Objective softprob) ---")
print("-------------------------------------------------------------")


# =============================================================
# ===                1. THI·∫æT L·∫¨P C·∫§U H√åNH                 ===
# =============================================================
# --- ƒê∆∞·ªùng d·∫´n Annotations ---
breast_level_csv = 'them data/breast-level_annotations.csv'
finding_level_csv = 'them data/finding_annotations.csv'
# --- ƒê∆∞·ªùng d·∫´n ·∫¢nh ---
image_base_dir = 'orr'# Th∆∞ m·ª•c CHA
train_dir_name = "train"
test_dir_name = "test"
IMAGE_EXTENSION = ".png" # <<<--- !!! KI·ªÇM TRA V√Ä C·∫¨P NH·∫¨T ƒêU√îI FILE !!!
# --- ƒê∆∞·ªùng d·∫´n Output ---
output_dir = "classification_output_v7_softprob" # Th∆∞ m·ª•c output
os.makedirs(output_dir, exist_ok=True) # T·∫°o th∆∞ m·ª•c n·∫øu ch∆∞a c√≥
output_processed_csv_path = os.path.join(output_dir, "final_processed_annotations.csv")
output_model_path = os.path.join(output_dir, "xgboost_birads_model_core_softprob.json")
output_report_path = os.path.join(output_dir, "classification_results.txt")
output_training_plot_path = os.path.join(output_dir, "training_performance_curve.png")
output_cm_plot_path = os.path.join(output_dir, "confusion_matrix_heatmap.png")
output_roc_plot_path = os.path.join(output_dir, "roc_curves_ovr.png")
output_pr_plot_path = os.path.join(output_dir, "precision_recall_curves_ovr1.png")
# --- C·∫•u h√¨nh K·∫øt h·ª£p & Ph√¢n lo·∫°i ---
KEY_COLUMNS = ['image_id']; IMAGE_PATH_COL = 'image_path'
MODEL_NAME = 'resnet50'; FEATURE_VECTOR_SIZE = 2048; IMAGE_SIZE = (224, 224)
# Params cho xgb.train (API c·ªët l√µi) - S·ª¨ D·ª§NG SOFTPROB
XGB_PARAMS = {
    'max_depth': 7, 'learning_rate': 0.1,
    'objective': 'multi:softprob', # <<<--- ƒê·ªîI SANG SOFTPROB
    'eval_metric': 'mlogloss',
    'random_state': 42, 'nthread': -1
}
NUM_BOOST_ROUND = 400 # S·ªë c√¢y t·ªëi ƒëa
EARLY_STOPPING_ROUNDS = 60 # S·ªë v√≤ng d·ª´ng s·ªõm
TEST_SIZE = 0.2; RANDOM_STATE = 42
METADATA_COLS_FOR_MODEL = ['view_position', 'breast_density', 'laterality']; TARGET_COL = 'breast_birads'
print(f"üìÇ Th∆∞ m·ª•c Output: {os.path.abspath(output_dir)}")




# =============================================================
# ===          2. ƒê·ªåC, L·ªåC V√Ä K·∫æT H·ª¢P ANNOTATIONS          ===
# =============================================================
print("\n[B∆∞·ªõc 1/8] ƒê·ªçc, l·ªçc v√† k·∫øt h·ª£p annotations...")
start_step_time = time.time()
# Ki·ªÉm tra file
if not os.path.exists(breast_level_csv): print(f"‚ùå L·ªói: Kh√¥ng t√¨m th·∫•y file '{breast_level_csv}'"); exit()
if not os.path.exists(finding_level_csv): print(f"‚ùå L·ªói: Kh√¥ng t√¨m th·∫•y file '{finding_level_csv}'"); exit()
print(f"   - T√¨m th·∫•y '{os.path.basename(breast_level_csv)}'.")
print(f"   - T√¨m th·∫•y '{os.path.basename(finding_level_csv)}'.")
# ƒê·ªçc file
try: df_breast = pd.read_csv(breast_level_csv); print(f"   - ƒê·ªçc {len(df_breast)} d√≤ng t·ª´ '{os.path.basename(breast_level_csv)}'.")
except Exception as e: print(f"‚ùå L·ªói khi ƒë·ªçc file CSV '{breast_level_csv}': {e}"); exit()
try: df_finding = pd.read_csv(finding_level_csv); print(f"   - ƒê·ªçc {len(df_finding)} d√≤ng t·ª´ '{os.path.basename(finding_level_csv)}'.")
except Exception as e: print(f"‚ùå L·ªói khi ƒë·ªçc file CSV '{finding_level_csv}': {e}"); exit()
# Ki·ªÉm tra c·ªôt kh√≥a
missing_keys_breast = [col for col in KEY_COLUMNS if col not in df_breast.columns]; missing_keys_finding = [col for col in KEY_COLUMNS if col not in df_finding.columns]
if missing_keys_breast: print(f"‚ùå L·ªói: File '{os.path.basename(breast_level_csv)}' thi·∫øu c·ªôt kh√≥a: {missing_keys_breast}"); exit()
if missing_keys_finding: print(f"‚ùå L·ªói: File '{os.path.basename(finding_level_csv)}' thi·∫øu c·ªôt kh√≥a: {missing_keys_finding}"); exit()
print(f"   - C·ªôt kh√≥a {KEY_COLUMNS} t·ªìn t·∫°i.")
# X√°c ƒë·ªãnh c·ªôt chung v√† l·ªçc
common_columns = list(set(df_breast.columns) & set(df_finding.columns)); print(f"   - X√°c ƒë·ªãnh {len(common_columns)} c·ªôt chung.")
df_breast_common = df_breast[common_columns].copy(); df_finding_common = df_finding[common_columns].copy()
# Merge
print(f"   - Th·ª±c hi·ªán 'inner' join tr√™n {KEY_COLUMNS}...")
merged_df = pd.merge(df_breast_common, df_finding_common, on=KEY_COLUMNS, how='inner', suffixes=('_breast', '_finding'))
# X·ª≠ l√Ω c·ªôt tr√πng t√™n (∆∞u ti√™n _breast)
processed_cols = set(); final_cols = []
for col in merged_df.columns:
    base_col = col.replace('_breast', '').replace('_finding', '')
    if base_col not in processed_cols:
        if f"{base_col}_breast" in merged_df.columns: merged_df[base_col] = merged_df[f"{base_col}_breast"]
        elif f"{base_col}_finding" in merged_df.columns: merged_df[base_col] = merged_df[f"{base_col}_finding"]
        elif base_col in merged_df.columns: pass
        else: continue
        final_cols.append(base_col); processed_cols.add(base_col)
merged_df = merged_df[final_cols]
print(f"   - S·ªë d√≤ng sau khi 'inner' join: {len(merged_df)}")
# X·ª≠ l√Ω tr√πng l·∫∑p
initial_merged_rows = len(merged_df); merged_df.drop_duplicates(subset=KEY_COLUMNS, keep='first', inplace=True)
duplicates_dropped = initial_merged_rows - len(merged_df)
if duplicates_dropped > 0: print(f"   - ƒê√£ lo·∫°i b·ªè {duplicates_dropped} b·∫£n ghi tr√πng l·∫∑p.")
print(f"   - S·ªë d√≤ng cu·ªëi c√πng trong DataFrame k·∫øt h·ª£p: {len(merged_df)}")
if merged_df.empty: print("‚ùå L·ªói: Kh√¥ng c√≥ d·ªØ li·ªáu chung. K·∫øt th√∫c."); exit()
end_step_time = time.time(); print(f"‚úÖ K·∫øt h·ª£p annotations ho√†n t·∫•t (Th·ªùi gian: {end_step_time - start_step_time:.2f}s).")
del df_breast, df_finding, df_breast_common, df_finding_common # Gi·∫£i ph√≥ng b·ªô nh·ªõ
gc.collect()




# =============================================================
# ===     3. T·∫†O ƒê∆Ø·ªúNG D·∫™N ·∫¢NH V√Ä KI·ªÇM TRA D·ªÆ LI·ªÜU        ===
# =============================================================
print("\n[B∆∞·ªõc 2/8] T·∫°o ƒë∆∞·ªùng d·∫´n ·∫£nh v√† ki·ªÉm tra d·ªØ li·ªáu k·∫øt h·ª£p...")
start_step_time = time.time()
# Ki·ªÉm tra c·ªôt c·∫ßn thi·∫øt
if 'split' not in merged_df.columns: print(f"‚ùå L·ªói: Thi·∫øu c·ªôt 'split'."); exit()
if 'image_id' not in merged_df.columns: print(f"‚ùå L·ªói: Thi·∫øu c·ªôt 'image_id'."); exit()
# H√†m t·∫°o ƒë∆∞·ªùng d·∫´n
def create_image_path(row):
    """T·∫°o ƒë∆∞·ªùng d·∫´n t∆∞∆°ng ƒë·ªëi d·ª±a tr√™n split v√† image_id."""
    # !!! ƒêI·ªÄU CH·ªàNH LOGIC N√ÄY N·∫æU C√ì TH∆Ø M·ª§C CON (patient_id/study_id) !!!
    split_folder = train_dir_name if row['split'] == 'training' else test_dir_name
    image_filename = f"{row['image_id']}{IMAGE_EXTENSION}"
    # V√≠ d·ª• kh√¥ng c√≥ th∆∞ m·ª•c con:
    path = os.path.join(split_folder, image_filename)
    return path
print(f"   - T·∫°o c·ªôt '{IMAGE_PATH_COL}' v·ªõi ƒëu√¥i file '{IMAGE_EXTENSION}'...")
merged_df[IMAGE_PATH_COL] = merged_df.apply(create_image_path, axis=1)
if merged_df[IMAGE_PATH_COL].isnull().any(): print("   ‚ö†Ô∏è C·∫£nh b√°o: C√≥ l·ªói khi t·∫°o ƒë∆∞·ªùng d·∫´n ·∫£nh."); merged_df.dropna(subset=[IMAGE_PATH_COL], inplace=True)
print(f"     V√≠ d·ª• ƒë∆∞·ªùng d·∫´n: {merged_df[IMAGE_PATH_COL].iloc[0]}" if not merged_df.empty else "     (Kh√¥ng c√≥ d·ªØ li·ªáu)")
# Ki·ªÉm tra c·ªôt c·∫ßn thi·∫øt cho model
required_cols_model = [IMAGE_PATH_COL] + METADATA_COLS_FOR_MODEL + [TARGET_COL]
missing_cols_model = [col for col in required_cols_model if col not in merged_df.columns]
if missing_cols_model: print(f"‚ùå L·ªói: DataFrame thi·∫øu c·ªôt cho m√¥ h√¨nh: {missing_cols_model}"); exit()
print(f"   - C√°c c·ªôt c·∫ßn thi·∫øt ({required_cols_model}) ƒë√£ t·ªìn t·∫°i.")
# X·ª≠ l√Ω NaN
initial_rows = len(merged_df); merged_df.dropna(subset=required_cols_model, inplace=True)
dropped_rows = initial_rows - len(merged_df)
if dropped_rows > 0: print(f"   - ƒê√£ lo·∫°i b·ªè {dropped_rows} d√≤ng ch·ª©a gi√° tr·ªã thi·∫øu.")
print(f"   - S·ªë d√≤ng h·ª£p l·ªá sau khi lo·∫°i b·ªè NaN: {len(merged_df)}")
if merged_df.empty: print("‚ùå L·ªói: Kh√¥ng c√≤n d·ªØ li·ªáu h·ª£p l·ªá."); exit()
# M√£ h√≥a
print("   - M√£ h√≥a metadata v√† nh√£n...")
le_view = LabelEncoder(); le_laterality = LabelEncoder(); le_density = LabelEncoder(); le_birads = LabelEncoder()
try:
    merged_df['view_position_encoded'] = le_view.fit_transform(merged_df['view_position'])
    merged_df['laterality_encoded'] = le_laterality.fit_transform(merged_df['laterality'])
    if not pd.api.types.is_numeric_dtype(merged_df['breast_density']): merged_df['breast_density_encoded'] = le_density.fit_transform(merged_df['breast_density'])
    else: merged_df['breast_density_encoded'] = merged_df['breast_density']
    merged_df['birads_encoded'] = le_birads.fit_transform(merged_df[TARGET_COL])
    num_classes = len(le_birads.classes_); target_names = [str(cls) for cls in le_birads.classes_]
    XGB_PARAMS['num_class'] = num_classes # C·∫≠p nh·∫≠t tham s·ªë XGBoost
    print(f"     - ƒê√£ m√£ h√≥a c√°c c·ªôt. S·ªë l·ªõp BI-RADS: {num_classes}")
except KeyError as ke: print(f"‚ùå L·ªói KeyError khi m√£ h√≥a c·ªôt: {ke}."); exit()
except Exception as e: print(f"‚ùå L·ªói kh√¥ng x√°c ƒë·ªãnh khi m√£ h√≥a: {e}"); exit()
end_step_time = time.time(); print(f"‚úÖ Ti·ªÅn x·ª≠ l√Ω d·ªØ li·ªáu k·∫øt h·ª£p ho√†n t·∫•t (Th·ªùi gian: {end_step_time - start_step_time:.2f}s).")




# =============================================================
# ===          4. THI·∫æT L·∫¨P TR√çCH XU·∫§T ƒê·∫∂C TR∆ØNG           ===
# =============================================================
print("\n[B∆∞·ªõc 3/8] Thi·∫øt l·∫≠p m√¥ h√¨nh tr√≠ch xu·∫•t ƒë·∫∑c tr∆∞ng ·∫£nh...")
start_step_time = time.time()
image_transforms = transforms.Compose([transforms.Resize(IMAGE_SIZE), transforms.ToTensor(), transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])])
device = torch.device("cuda" if torch.cuda.is_available() else "cpu"); print(f"   - S·ª≠ d·ª•ng thi·∫øt b·ªã: {str(device).upper()}")
print(f"   - T·∫£i m√¥ h√¨nh {MODEL_NAME} pretrained...");
try:
    cnn_model = None
    if MODEL_NAME == 'resnet50': cnn_model = models.resnet50(weights=models.ResNet50_Weights.IMAGENET1K_V2); cnn_model.fc = nn.Identity()
    elif MODEL_NAME == 'resnet101': cnn_model = models.resnet101(weights=models.ResNet101_Weights.IMAGENET1K_V2); cnn_model.fc = nn.Identity()
    else: print(f"‚ùå L·ªói: Model '{MODEL_NAME}' kh√¥ng ƒë∆∞·ª£c h·ªó tr·ª£."); exit()
    if cnn_model: cnn_model = cnn_model.to(device); cnn_model.eval()
    else: print("‚ùå L·ªói: Kh√¥ng th·ªÉ kh·ªüi t·∫°o cnn_model."); exit()
    end_step_time = time.time(); print(f"‚úÖ T·∫£i v√† c·∫•u h√¨nh {MODEL_NAME} th√†nh c√¥ng (Th·ªùi gian: {end_step_time - start_step_time:.2f}s).")
except Exception as e: print(f"‚ùå L·ªói khi t·∫£i/c·∫•u h√¨nh CNN: {e}"); exit()




# =============================================================
# ===             5. TR√çCH XU·∫§T ƒê·∫∂C TR∆ØNG ·∫¢NH              ===
# =============================================================
# ==== ƒê·ªãnh nghƒ©a LABEL_COL ====
# ==== Chu·∫©n b·ªã th∆∞ m·ª•c l∆∞u ·∫£nh augment ====
# ==== Chu·∫©n b·ªã th∆∞ m·ª•c l∆∞u ·∫£nh augment ====
import os
import time
import gc
import numpy as np
import torch
import torchvision.transforms as transforms
from tqdm import tqdm
from PIL import Image, UnidentifiedImageError
import matplotlib.pyplot as plt

augmented_images_dir = "augmented_images2"
os.makedirs(augmented_images_dir, exist_ok=True)

LABEL_COL = 'birads_encoded'

print("\n[B∆∞·ªõc 4/8] B·∫Øt ƒë·∫ßu tr√≠ch xu·∫•t ƒë·∫∑c tr∆∞ng ·∫£nh (augment nh√£n 2,3,4 ƒë·ªÉ c√¢n b·∫±ng v·ªõi nh√£n 1)...")
start_step_time = time.time()

# ==== Augmentation nh·∫π cho nh√£n 2,3 ====
light_augment = transforms.Compose([
    transforms.RandomHorizontalFlip(p=0.5),
    transforms.RandomRotation(degrees=5),
    transforms.ColorJitter(brightness=0.1, contrast=0.1),
    transforms.RandomAffine(degrees=3, translate=(0.02, 0.02), scale=(0.98, 1.02)),
    transforms.RandomResizedCrop(size=(224, 224), scale=(0.85, 1.0)),
])

# ==== Augmentation m·∫°nh cho nh√£n 4 ====
strong_augment = transforms.Compose([
    transforms.RandomHorizontalFlip(p=0.7),
    transforms.RandomVerticalFlip(p=0.5),
    transforms.RandomRotation(degrees=15),
    transforms.ColorJitter(brightness=0.3, contrast=0.3, saturation=0.2),
    transforms.RandomAffine(degrees=10, translate=(0.1, 0.1), scale=(0.8, 1.2), shear=10),
    transforms.RandomPerspective(distortion_scale=0.4, p=0.5),
    transforms.RandomResizedCrop(size=(224, 224), scale=(0.7, 1.0)),
])

# ==== H√†m extract feature t·ª´ PIL Image ====
def extract_feature_from_pil(img):
    img_tensor = image_transforms(img).unsqueeze(0).to(device)
    with torch.no_grad():
        feature_vector = cnn_model(img_tensor).squeeze().cpu().numpy()
    if np.isnan(feature_vector).any():
        return None
    return feature_vector

# ==== C√°c bi·∫øn l∆∞u tr·ªØ trung gian ====
features_list = []
valid_indices_processed = []
augmentation_flags = []
skipped_files_count = 0
augment_image_count = 0

# ==== X√°c ƒë·ªãnh s·ªë l∆∞·ª£ng nh√£n hi·ªán t·∫°i ====
label_counts = merged_df[LABEL_COL].value_counts()
print(f"üîé S·ªë l∆∞·ª£ng ban ƒë·∫ßu: {dict(label_counts)}")

augment_labels = [2, 3, 4]  
target_per_label = 8000  # M·ªói nh√£n augment t·ªõi 5000 ·∫£nh (t√≠nh c·∫£ g·ªëc v√† augment)

current_augmented_counts = {label: label_counts.get(label, 0) for label in augment_labels}
print(f"üéØ M·ª•c ti√™u s·ªë l∆∞·ª£ng cho m·ªói nh√£n: {target_per_label}")

# ==== X·ª≠ l√Ω t·ª´ng ·∫£nh ====
for idx, row in tqdm(merged_df.iterrows(), total=len(merged_df), desc="   Tr√≠ch xu·∫•t", unit="·∫£nh"):
    img_rel_path = row['image_path']
    img_full_path = os.path.join(image_base_dir, img_rel_path)
    label = row[LABEL_COL]

    try:
        img = Image.open(img_full_path).convert('RGB')

        # Tr√≠ch ƒë·∫∑c tr∆∞ng t·ª´ ·∫£nh g·ªëc
        feat = extract_feature_from_pil(img)
        if feat is not None and feat.shape == (FEATURE_VECTOR_SIZE,):
            features_list.append(feat)
            valid_indices_processed.append(idx)
            augmentation_flags.append(False)

            # N·∫øu c·∫ßn augment th√™m
            if label in augment_labels:
                while current_augmented_counts[label] < target_per_label:
                    aug = strong_augment if label == 4 else light_augment
                    aug_img = aug(img)

                    aug_feat = extract_feature_from_pil(aug_img)
                    if aug_feat is not None and aug_feat.shape == (FEATURE_VECTOR_SIZE,):
                        features_list.append(aug_feat)
                        valid_indices_processed.append(idx)
                        augmentation_flags.append(True)
                        augment_image_count += 1
                        current_augmented_counts[label] += 1

                        # L∆∞u ·∫£nh augment
                        orig_filename = os.path.splitext(os.path.basename(img_rel_path))[0]
                        aug_filename = f"{orig_filename}_aug{augment_image_count}.jpg"
                        aug_save_path = os.path.join(augmented_images_dir, aug_filename)
                        aug_img.save(aug_save_path)
                    else:
                        break  # N·∫øu l·ªói feature th√¨ d·ª´ng augment cho ·∫£nh n√†y

        else:
            skipped_files_count += 1

    except (FileNotFoundError, UnidentifiedImageError):
        skipped_files_count += 1
    except Exception as e:
        skipped_files_count += 1
        # print(f"‚ö†Ô∏è L·ªói x·ª≠ l√Ω ·∫£nh {img_full_path}: {e}")

end_step_time = time.time()

# ==== Th·ªëng k√™ k·∫øt qu·∫£ ====
print(f"‚úÖ Tr√≠ch xu·∫•t ho√†n t·∫•t (Th·ªùi gian: {end_step_time - start_step_time:.2f}s).")
print(f"   - S·ªë l∆∞·ª£ng ·∫£nh g·ªëc th√†nh c√¥ng: {len(merged_df) - skipped_files_count}")
print(f"   - S·ªë l∆∞·ª£ng ·∫£nh augment t·∫°o th√™m: {augment_image_count}")
print(f"   - T·ªïng s·ªë feature vector (g·ªëc + augment): {len(features_list)}")
print(f"   - S·ªë l∆∞·ª£ng m·ªõi sau augment: {current_augmented_counts}")
if skipped_files_count > 0:
    print(f"   - ·∫¢nh b·ªã l·ªói ho·∫∑c b·ªè qua: {skipped_files_count}")
if not features_list:
    print("‚ùå L·ªói: Kh√¥ng tr√≠ch xu·∫•t ƒë∆∞·ª£c b·∫•t k·ª≥ ƒë·∫∑c tr∆∞ng n√†o!")
    exit()

# ==== T·∫°o DataFrame sau x·ª≠ l√Ω ====
df_final = merged_df.loc[valid_indices_processed].reset_index(drop=True)
df_final['is_augmented'] = augmentation_flags
image_features = np.stack(features_list)
print(f"   - K√≠ch th∆∞·ªõc m·∫£ng ƒë·∫∑c tr∆∞ng: {image_features.shape}")

# ==== L∆∞u file CSV k·∫øt qu·∫£ ====
try:
    df_final.to_csv(output_processed_csv_path, index=False)
    print(f"üíæ ƒê√£ l∆∞u DataFrame ƒë√£ x·ª≠ l√Ω v√†o: {output_processed_csv_path}")
except Exception as e:
    print(f"‚ö†Ô∏è L·ªói khi l∆∞u file CSV: {e}")

# ==== D·ªçn b·ªô nh·ªõ ====
del merged_df, features_list
gc.collect()
torch.cuda.empty_cache() if device == 'cuda' else None

# ==== V·∫Ω bi·ªÉu ƒë·ªì ====
print("\nüìä V·∫Ω bi·ªÉu ƒë·ªì ph√¢n ph·ªëi label (g·ªëc + augment)...")

df_plot = df_final.copy()
df_plot['label'] = df_plot[LABEL_COL]

plt.figure(figsize=(10,6))
df_plot.groupby(['label', 'is_augmented']).size().unstack(fill_value=0).plot(
    kind='bar', stacked=True, ax=plt.gca(), color=['skyblue', 'salmon']
)
plt.title('S·ªë l∆∞·ª£ng ·∫£nh g·ªëc v√† augment theo t·ª´ng label')
plt.xlabel('Label')
plt.ylabel('S·ªë l∆∞·ª£ng ·∫£nh')
plt.legend(['·∫¢nh g·ªëc', '·∫¢nh augment'])
plt.grid(True)
plt.tight_layout()
plt.show()

# =============================================================
# ===         6. K·∫æT H·ª¢P ƒê·∫∂C TR∆ØNG CU·ªêI & CHIA D·ªÆ LI·ªÜU       ===
# =============================================================
print("\n[B∆∞·ªõc 5/8] K·∫øt h·ª£p ƒë·∫∑c tr∆∞ng ·∫£nh v√† metadata cu·ªëi c√πng...")
start_step_time = time.time()

try:
    metadata_cols = ['view_position_encoded', 'breast_density_encoded', 'laterality_encoded']
    metadata_features = df_final[metadata_cols].values
    metadata_scaled = StandardScaler().fit_transform(metadata_features)
    print("   - ƒê√£ √°p d·ª•ng StandardScaler cho metadata.")

    X = np.hstack([image_features, metadata_scaled])
    y = df_final['birads_encoded'].values
    print(f"   - K√≠ch th∆∞·ªõc X: {X.shape}, y: {y.shape}")

except KeyError as ke:
    print(f"‚ùå L·ªói KeyError: {ke}. Ki·ªÉm tra l·∫°i METADATA_COLS_FOR_MODEL."); exit()
except Exception as e:
    print(f"‚ùå L·ªói khi k·∫øt h·ª£p ƒë·∫∑c tr∆∞ng: {e}"); exit()

print(f"‚úÖ Ho√†n t·∫•t (Th·ªùi gian: {time.time() - start_step_time:.2f}s).")

# =============================================================
# ===                  6.1. CHIA D·∫Æ LI·ªÜU                   ===
# =============================================================
print("\n[B∆∞·ªõc 6/8] Chia d·ªØ li·ªáu th√†nh t·∫≠p hu·∫•n luy·ªán v√† ki·ªÉm tra...")
start_step_time = time.time()

try:
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=TEST_SIZE, stratify=y, random_state=RANDOM_STATE
    )
    print(f"   - T·∫≠p Train: X={X_train.shape}, y={y_train.shape}")
    print(f"   - T·∫≠p Test : X={X_test.shape}, y={y_test.shape}")
except Exception as e:
    print(f"‚ùå L·ªói khi chia d·ªØ li·ªáu: {e}"); exit()

print(f"‚úÖ Ho√†n t·∫•t (Th·ªùi gian: {time.time() - start_step_time:.2f}s).")

# =============================================================
# ===              7. HU·∫§N LUY·ªÜN & L∆ØU M√î H√åNH (SVM)        ===
# =============================================================
from sklearn.svm import SVC
import pickle

print("\n[B∆∞·ªõc 7/8] Hu·∫•n luy·ªán m√¥ h√¨nh SVM v√† l∆∞u model...")
start_step_time = time.time()

try:
    clf = SVC(probability=True, random_state=RANDOM_STATE)
    clf.fit(X_train, y_train)
    print("   - Hu·∫•n luy·ªán SVM th√†nh c√¥ng.")

    # L∆∞u model
    with open(output_model_path, 'wb') as f:
        pickle.dump(clf, f)
    print(f"     üìÖ L∆∞u m√¥ h√¨nh v√†o: {output_model_path}")
except Exception as e:
    print(f"‚ùå L·ªói hu·∫•n luy·ªán/l∆∞u SVM: {e}")

print(f"‚úÖ Ho√†n t·∫•t (Th·ªùi gian: {time.time() - start_step_time:.2f}s).")

# =============================================================
# ===             8. ƒê√ÅNH GI√Å & L∆ØU K·∫æT QU·∫¢                ===
# =============================================================
print("\n[B∆∞·ªõc 8/8] ƒê√°nh gi√° m√¥ h√¨nh v√† l∆∞u k·∫øt qu·∫£...")
start_step_time = time.time()

metrics_ready = False

try:
    y_pred_proba = clf.predict_proba(X_test)
    y_pred = clf.predict(X_test)
    y_true = y_test.astype(int)
    metrics_ready = True
except Exception as e:
    print(f"‚ùå L·ªói d·ª± ƒëo√°n: {e}")

accuracy = -1.0
if metrics_ready:
    try:
        accuracy = accuracy_score(y_true, y_pred)
        report = classification_report(y_true, y_pred, target_names=target_names, zero_division=0)
        cm = confusion_matrix(y_true, y_pred, labels=range(num_classes))
        cm_df = pd.DataFrame(cm, index=le_birads.classes_, columns=le_birads.classes_)
    except Exception as e:
        print(f"‚ùå L·ªói khi t√≠nh to√°n metrics: {e}")
        metrics_ready = False

if metrics_ready:
    print(f"\n   - ƒê·ªô ch√≠nh x√°c: {accuracy:.4f}")
    print("\n   - Classification Report:\n", report)
    print("\n   - Confusion Matrix:\n", cm_df)

    # Heatmap CM
    fig_cm, ax_cm = plt.subplots(figsize=(8, 6))
    sns.heatmap(cm_df, annot=True, fmt='d', cmap='Blues', ax=ax_cm)
    ax_cm.set_xlabel('Predicted'); ax_cm.set_ylabel('True'); ax_cm.set_title('Confusion Matrix')
    plt.tight_layout(); plt.savefig(output_cm_plot_path); plt.close()
    print(f"     üìÖ ƒê√£ l∆∞u heatmap CM: {output_cm_plot_path}")

    # ROC Curve
    try:
        y_true_bin = label_binarize(y_true, classes=range(num_classes))
        fig_roc, ax_roc = plt.subplots(figsize=(10, 7))
        for i in range(num_classes):
            fpr, tpr, _ = roc_curve(y_true_bin[:, i], y_pred_proba[:, i])
            roc_auc = auc(fpr, tpr)
            ax_roc.plot(fpr, tpr, label=f'{target_names[i]} (AUC={roc_auc:.2f})')
        ax_roc.plot([0, 1], [0, 1], 'k--'); ax_roc.legend(); ax_roc.grid(True)
        ax_roc.set_xlabel('False Positive Rate'); ax_roc.set_ylabel('True Positive Rate')
        ax_roc.set_title('ROC Curve')
        plt.tight_layout(); plt.savefig(output_roc_plot_path); plt.close()
        print(f"     üìÖ ƒê√£ l∆∞u ROC Curve: {output_roc_plot_path}")
    except Exception as e:
        print(f"‚ö†Ô∏è L·ªói v·∫Ω ROC: {e}")

    # PR Curve
    try:
        fig_pr, ax_pr = plt.subplots(figsize=(10, 7))
        for i in range(num_classes):
            precision, recall, _ = precision_recall_curve(y_true_bin[:, i], y_pred_proba[:, i])
            ap = average_precision_score(y_true_bin[:, i], y_pred_proba[:, i])
            ax_pr.plot(recall, precision, label=f'{target_names[i]} (AP={ap:.2f})')
        ax_pr.legend(); ax_pr.grid(True)
        ax_pr.set_xlabel('Recall'); ax_pr.set_ylabel('Precision')
        ax_pr.set_title('Precision-Recall Curve')
        plt.tight_layout(); plt.savefig(output_pr_plot_path); plt.close()
        print(f"     üìÖ ƒê√£ l∆∞u PR Curve: {output_pr_plot_path}")
    except Exception as e:
        print(f"‚ö†Ô∏è L·ªói v·∫Ω PR: {e}")

# L∆∞u report txt
print(f"\n   - L∆∞u k·∫øt qu·∫£ v√†o: {output_report_path}")
try:
    total_duration = time.time() - script_start_time_main
    with open(output_report_path, 'w', encoding='utf-8') as f:
        f.write("="*53 + "\n")
        f.write("===       K·∫æT QU·∫¢ ƒê√ÅNH GI√Å M√î H√åNH PH√ÇN LO·∫†I BI-RADS       ===\n")
        f.write("="*53 + "\n\n")
        f.write(f"T·ªïng th·ªùi gian: {total_duration:.2f} gi√¢y ({total_duration/60:.2f} ph√∫t)\n\n")
        f.write(f"C·∫•u h√¨nh:\n  - Model: {MODEL_NAME}\n  - IMAGE_SIZE: {IMAGE_SIZE}\n")
        f.write(f"  - Classifier: SVM\n  - Test size: {TEST_SIZE:.2%}\n  - Num classes: {num_classes}\n\n")
        if metrics_ready:
            f.write(f"Accuracy: {accuracy:.4f}\n\nClassification Report:\n{report}\n\n")
            f.write(f"Confusion Matrix:\n{cm_df.to_string()}\n\n")
        else:
            f.write("L·ªói khi t√≠nh to√°n metrics.\n")
        f.write("="*53 + "\n")
    print("     üìÖ ƒê√£ l∆∞u b√°o c√°o.")
except Exception as e:
    print(f"‚ö†Ô∏è L·ªói khi l∆∞u b√°o c√°o: {e}")

print("\nüìÖ Ho√†n t·∫•t ƒë√°nh gi√° v√† l∆∞u k·∫øt qu·∫£ (Th·ªùi gian: {:.2f}s).".format(time.time() - start_step_time))
print("\n-------------------------------------------------------------")
print("--- Quy tr√¨nh K·∫øt h·ª£p v√† Ph√¢n lo·∫°i BI-RADS Ho√†n t·∫•t ---")
print("-------------------------------------------------------------")

 

